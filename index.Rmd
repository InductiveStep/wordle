---
title: "Wordle helper (or, how to cheat at Wordle)"
author: "Andi Fugard"
date: "09/01/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


This is my approach to solving/cheating at [Wordle](https://www.powerlanguage.co.uk/wordle/).


### Package(s)

First, get the {tidyverse} loaded:

```{r warning=FALSE}
library(tidyverse)
```

We won't need anything else that's not already in base R.

### Words

We'll need a dictionary. I wanted word frequencies too, since we know that the game has about 2,000 words in total and I assume they have been selected so it's possible to guess them in six moves. After being dissatisfied with dictionaries built into CRAN packages, my wander around the web led me to [Wiktionary](https://en.wiktionary.org/)'s page on [frequency lists](https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists#English). I (arbitrarily) opted for a [dataset](https://github.com/hermitdave/FrequencyWords/) developed by analysing an open subtitle corpus.

Let's grab it directly from the GitHub repo:

```{r}
words <-
  read.csv(
    "https://raw.githubusercontent.com/hermitdave/FrequencyWords/master/content/2018/en/en_full.txt",
    sep = " ",
    header = FALSE
  )
names(words) <- c("word", "freq")
```

And take a look:

```{r}
head(words, 10)
```
So the word "you" appears 28.8 million times in the corpus.

Next, filter to only words of length 5 and tidy a little to remove words with apostrophes and other non-letter characters.

```{r}
wordles <- words %>%
  filter(str_length(word) == 5) %>%
  mutate(word = str_to_lower(word)) %>%
  filter(str_detect(word, "^[a-z]*$")) %>%
  arrange(desc(freq))
```

(The word list was already reverse sorted by frequency, but I've sorted again in case I slot in another word list later.)


```{r}
head(wordles, 10)
```

That looks better, though I'm not sure all those words are gonna to be a wordle. In retrospect a subtitle corpus wasn't ideal. Anyway, onwards...


### Helpers

Tidyverse and base R already have all the functions I need to filter this word list as we learn more about what letters are and are not in a wordle. I just want some helper functions to make them easier to use.

#### All words that have particular letters somewhere

```{r}
all_lets_somewhere <- Vectorize(function(str, lets) {
  all(str_detect(str, strsplit(lets, "")[[1]]))
}, vectorize.args = "str")
```

Here's how it works -- test whether "e" is in each word:

```{r}
all_lets_somewhere(c("lovely", "weather"), "e")
```

Test whether "e" and "w" are in each word:

```{r}
all_lets_somewhere(c("lovely", "weather"), "ew")
```


#### All words that don't have particular letters anywhere

```{r}
no_lets_anywhere <- Vectorize(function(str, lets) {
  !any(str_detect(str, strsplit(lets, "")[[1]]))
}, vectorize.args = "str")
```

Here's how it works -- test whether neither "z" nor "b" are in each word:

```{r}
no_lets_anywhere(c("zebra", "giraffe"), "zb")
```




#### Filter/keep words with letters in particular positions

Wordle's feedback can tell us that a letter is there somewhere but not in the position we guessed. `str_detect` already does what we need easily enough: a "." in a [regex](https://en.wikipedia.org/wiki/Regular_expression) matches any letter, so we can negate that. This is a wrapper for ease of piping:

```{r}
ditch_pattern <- function(data, match) {
  data %>%
    filter(!str_detect(word, match))
}
```

Here's how to use it. First, here's the top of the wordles data:

```{r}
wordles %>%
  head()
```

Let's remove the two words with "in" in their third and fourth characters:

```{r}
wordles %>% 
  head() %>%
  ditch_pattern("..in.")
```

`keep_pattern` works similarly:

```{r}
keep_pattern <- function(data, match) {
  data %>%
    filter(str_detect(word, match))
}
```

Here's an example:

```{r}
wordles %>% 
  head() %>%
  keep_pattern("..in.")
```

#### Final filter helpers

These functions just make it easier to use functions above in a pipe:

```{r}
ditch_letters <- function(data, match) {
  data %>%
    filter(no_lets_anywhere(word, match))
}

keep_letters <- function(data, match) {
  data %>%
    filter(all_lets_somewhere(word, match))
}
```


### Test drive

Let's give it a go. The example wordle I'm using here is from a few days ago, so hopefully no spoilers.

To get started, let's use the most frequent word that has a handful of vowels, "a", "i", and "e":

```{r}
wordles %>%
  keep_letters("aie") %>%
  head()
```

We have one hit!


![](wordle_1.png){width=200px}


So we want to keep all words with "L" in the second character and ditch the others:

```{r}
wordles %>%
  keep_pattern(".l...") %>%
  ditch_letters("aive") %>%
  head()
```

I'll just go for the most frequent word in the remaining data, "blood". (This may not always be the best idea, e.g., the letter "o" occurs twice in "blood"; it might be better to choose a different word with no duplicates and high frequency letters.)


![](wordle_2.png){width=200px}

No new matches, but we can ditch three more letters so all is not lost.

```{r}
wordles %>%
  keep_pattern(".l...") %>%
  ditch_letters("aivebod") %>%
  head()
```

Let's go for the most frequent word again:



![](wordle_3.png){width=200px}

More matches and letters to ditch to help narrow in on the answer. I have also removed words ending "s" as it seems unlikely wordles would just be plurals, and the top matches ending "s" weren't singular nouns ("dress" would be an example that is).

```{r}
wordles %>%
  keep_pattern(".lu..") %>%
  ditch_letters("aivebodfh") %>%
  keep_letters("s") %>%
  ditch_pattern("...s.") %>%
  ditch_pattern("....s") %>%
  head()
```

Again, let's go for the most frequent match:


![](wordle_4.png){width=200px}

And we're done.


### Revisiting the word list: letter frequency

Let's see whether frequency analysis can help us be a little cleverer in searching.

First, functions to count letter frequency.

```{r}
long_wordles <- function(wordles) {
  wordle_chars <- sapply(str_split(wordles$word, ""),
                         c) %>% 
  t()
  
  colnames(wordle_chars) <- paste("c", 1:5, sep = "_")
  
  bind_cols(wordles, wordle_chars %>% as_tibble()) %>%
  pivot_longer(cols = c_1:c_5,
               names_prefix = "c_",
               names_to = "pos",
               values_to = "let")
}
```

```{r}
letter_freqs <- function(wordles) {
  n_words <- nrow(wordles)
  
  wordles %>%
    long_wordles() %>%
    group_by(word, freq, let) %>%
    summarise(n = n()) %>%
    mutate(b = as.numeric(n > 0)) %>%
    ungroup() %>%
    group_by(let) %>%
    summarise(n = n()) %>%
    ungroup() %>%
    mutate(perc = 100*n/n_words) %>%
    arrange(desc(n))    
}
```

Get letter frequencies for 1000 most frequent words:

```{r}
wordles %>%
  head(1000) %>%
  letter_freqs()
```

The most frequent letters are "e", "a", "s", "r", and "o". Let's find a word with those letters:

```{r}
wordles %>%
  keep_letters("easro") %>%
  head()
```

Give it a go:

![](2nd_wordle_1.png){width=200px}

We can ditch some letters:

```{r}
wordles %>%
  keep_pattern (".r...") %>%
  keep_letters("a") %>%
  ditch_pattern("a....") %>%
  ditch_letters("ose") %>%
  head()
```
Now, rather than just take the most frequent word from this list, let's count letter frequencies again.

```{r}
wordles %>%
  keep_pattern (".r...") %>%
  keep_letters("a") %>%
  ditch_pattern("a....") %>%
  ditch_letters("ose") %>%
  letter_freqs()
```

Select a word with the most frequent two letters we don't already have:

```{r}
wordles %>%
  keep_pattern (".r...") %>%
  keep_letters("a") %>%
  ditch_pattern("a....") %>%
  ditch_letters("ose") %>%
  keep_letters("it") %>%
  head()
```

And so on...

It would be fun to automate this process a little more.
